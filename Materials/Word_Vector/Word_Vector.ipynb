{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Word Vector (a.k.a Word Embedding) </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Word2Vector\n",
    " - Vector representation of words (i.e. word vectors) learned using neural network\n",
    "   - e.g. \"apple\" : [0.35, -0.2, 0.4, ...], 'mongo':  [0.32, -0.18, 0.5, ...]\n",
    "   - Interesting properties of word vectors:\n",
    "    * **Words with similar semantics have close word vectors**\n",
    "    <img src=\"https://www.kdnuggets.com/images/cartoon-espresso-word2vec.jpg\" width=\"50%\">\n",
    "    https://www.kdnuggets.com/2017/04/cartoon-word2vec-espresso-cappuccino.html\n",
    "    * **Composition**: e.g. vector(\"woman\")+vector(\"king\")-vector('man') $\\approx$ vector(\"queen\")\n",
    " - Models:\n",
    "   - **CBOW** (Continuous Bag of Words): Predict a target word based on context\n",
    "     - e.g. the fox jumped over the lazy dog\n",
    "     - Assuming symmetric context with window size 3, this sentence can create training samples: \n",
    "       - ([-, fox], the) \n",
    "       - ([the, jumped], fox) \n",
    "       - ([fox, over], jumped)\n",
    "       - ([jumped, the], over) \n",
    "       - ...\n",
    "       \n",
    "       <img src=\"cbow.png\" width=\"50%\">\n",
    "       source: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "   - **Skip Gram**: predict context based on target words\n",
    "   \n",
    "        <img src=\"skip_gram.png\" width=\"50%\">\n",
    "        source: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up interactive shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a little longer and more detailed than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Only Michelle Branch save this album!!!!All gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A surprisingly good book, given its inherently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a wonderful, quiet and relaxing CD tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The lights that I received are absolutely not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      2  This is a little longer and more detailed than...\n",
       "1      1  Only Michelle Branch save this album!!!!All gu...\n",
       "2      2  A surprisingly good book, given its inherently...\n",
       "3      2  This is a wonderful, quiet and relaxing CD tha...\n",
       "4      1  The lights that I received are absolutely not ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'little', 'longer', 'and', 'more', 'detailed', 'than', 'the', 'first', 'two', 'books', 'in', 'the', 'series', 'however', 'have', 'enjoyed', 'each', 'new', 'aspect', 'of', 'the', 'exciting', 'fantasy', 'universe'], ['only', 'michelle', 'branch', 'save', 'this', 'album', 'all', 'guys', 'play', 'along', 'with', 'unenthusiastic', 'beat', 'even', 'karl']]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.1 Train your word vector\n",
    "\n",
    "import pandas as pd\n",
    "import nltk,string\n",
    "\n",
    "# Load data\n",
    "data=pd.read_csv('amazon_review_large.csv')\n",
    "data.columns=['label','text']\n",
    "data.head()\n",
    "\n",
    "# tokenize each document into a list of unigrams\n",
    "# strip punctuations and leading/trailing spaces from unigrams\n",
    "# only unigrams with 2 or more characters are taken\n",
    "sentences=[ [token.strip(string.punctuation).strip() \\\n",
    "             for token in nltk.word_tokenize(doc.lower()) \\\n",
    "                 if token not in string.punctuation and \\\n",
    "                 len(token.strip(string.punctuation).strip())>=2]\\\n",
    "             for doc in data[\"text\"]]\n",
    "print(sentences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:25:53,651 : INFO : collecting all words and their counts\n",
      "2023-04-24 20:25:53,651 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-04-24 20:25:53,709 : INFO : PROGRESS: at sentence #10000, processed 712099 words, keeping 36835 word types\n",
      "2023-04-24 20:25:53,767 : INFO : collected 55006 word types from a corpus of 1424497 raw words and 20000 sentences\n",
      "2023-04-24 20:25:53,767 : INFO : Creating a fresh vocabulary\n",
      "2023-04-24 20:25:53,789 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12138 unique words (22.07% of original 55006, drops 42868)', 'datetime': '2023-04-24T20:25:53.789491', 'gensim': '4.3.0', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.0-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-04-24 20:25:53,789 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1362451 word corpus (95.64% of original 1424497, drops 62046)', 'datetime': '2023-04-24T20:25:53.789899', 'gensim': '4.3.0', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.0-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-04-24 20:25:53,810 : INFO : deleting the raw counts dictionary of 55006 items\n",
      "2023-04-24 20:25:53,812 : INFO : sample=0.001 downsamples 57 most-common words\n",
      "2023-04-24 20:25:53,813 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1015978.4845063044 word corpus (74.6%% of prior 1362451)', 'datetime': '2023-04-24T20:25:53.812942', 'gensim': '4.3.0', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.0-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2023-04-24 20:25:53,851 : INFO : estimated required memory for 12138 words and 200 dimensions: 25489800 bytes\n",
      "2023-04-24 20:25:53,851 : INFO : resetting layer weights\n",
      "2023-04-24 20:25:53,860 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-04-24T20:25:53.860961', 'gensim': '4.3.0', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.0-arm64-arm-64bit', 'event': 'build_vocab'}\n",
      "2023-04-24 20:25:53,861 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 12138 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-04-24T20:25:53.861450', 'gensim': '4.3.0', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.0-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-04-24 20:25:54,218 : INFO : EPOCH 0: training on 1424497 raw words (1015828 effective words) took 0.4s, 2862957 effective words/s\n",
      "2023-04-24 20:25:54,570 : INFO : EPOCH 1: training on 1424497 raw words (1016420 effective words) took 0.4s, 2903074 effective words/s\n",
      "2023-04-24 20:25:54,928 : INFO : EPOCH 2: training on 1424497 raw words (1015827 effective words) took 0.4s, 2857457 effective words/s\n",
      "2023-04-24 20:25:55,278 : INFO : EPOCH 3: training on 1424497 raw words (1016313 effective words) took 0.3s, 2911710 effective words/s\n",
      "2023-04-24 20:25:55,651 : INFO : EPOCH 4: training on 1424497 raw words (1015679 effective words) took 0.4s, 2742798 effective words/s\n",
      "2023-04-24 20:25:55,651 : INFO : Word2Vec lifecycle event {'msg': 'training on 7122485 raw words (5080067 effective words) took 1.8s, 2838065 effective words/s', 'datetime': '2023-04-24T20:25:55.651710', 'gensim': '4.3.0', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.0-arm64-arm-64bit', 'event': 'train'}\n",
      "2023-04-24 20:25:55,651 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=12138, vector_size=200, alpha=0.025>', 'datetime': '2023-04-24T20:25:55.651984', 'gensim': '4.3.0', 'python': '3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]', 'platform': 'macOS-13.0-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Train your own word vectors using gensim\n",
    "\n",
    "# gensim.models is the package for word2vec\n",
    "# check https://radimrehurek.com/gensim/models/word2vec.html\n",
    "# for detailed description\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# print out tracking information\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \\\n",
    "                    level=logging.INFO)\n",
    "\n",
    "# min_count: words with total frequency lower than this are ignored\n",
    "# size: the dimension of word vector\n",
    "# window: context window, i.e. the maximum distance \n",
    "#         between the current and predicted word \n",
    "#         within a sentence (i.e. the length of ngrams)\n",
    "# workers: # of parallel threads in training\n",
    "# for other parameters, check https://radimrehurek.com/gensim/models/word2vec.html\n",
    "wv_model = word2vec.Word2Vec(sentences, \\\n",
    "            min_count=5, vector_size=200, \\\n",
    "            window=5, workers=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('metal', 0.7495978474617004),\n",
       " ('band', 0.7354978919029236),\n",
       " ('rock', 0.734889030456543),\n",
       " ('sounds', 0.728912353515625),\n",
       " ('lyrics', 0.7257303595542908)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound' but not relevant to 'film'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rock', 0.8026798963546753),\n",
       " ('pop', 0.7725368142127991),\n",
       " ('lyrics', 0.7640302181243896),\n",
       " ('songs', 0.723604679107666),\n",
       " ('dance', 0.7107803821563721)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'film':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9240011"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'city':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011460363"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word does not match with others in the list of ['sound', 'music', 'graphics', 'actor', 'book']:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'book'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vector for 'movie':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.6477697 , -0.08716024, -0.7663413 ,  0.39492884,  0.41591638,\n",
       "       -0.34538504,  0.8292576 ,  0.78898036, -1.7558291 ,  0.36882758,\n",
       "        0.25195068,  0.11592049, -0.25626892, -0.11291727, -2.0660846 ,\n",
       "       -0.07905724,  0.6604024 , -2.2833545 , -1.0439785 , -1.9629272 ,\n",
       "        0.22974417,  1.662248  ,  0.7451703 , -0.24151595, -0.8185099 ,\n",
       "        1.1783727 , -0.7498035 , -1.4821293 ,  1.8805578 ,  0.5167119 ,\n",
       "        0.12485462,  0.5936655 ,  0.24084656,  0.5730325 , -1.9867804 ,\n",
       "        2.1124964 , -2.386052  , -0.5164091 , -1.4818395 , -0.36165473,\n",
       "        0.7513265 , -0.7891387 ,  0.9208886 , -0.23379344, -0.11015029,\n",
       "        0.3218885 , -1.2769501 , -0.2992271 ,  0.46782425,  0.88528115,\n",
       "       -1.3294902 , -0.5242811 ,  0.44653422,  0.15804431, -0.37007388,\n",
       "       -0.89891547, -0.01448711, -1.2937596 ,  0.03077303,  0.9326934 ,\n",
       "        0.9574108 ,  0.35496035,  0.348438  , -0.26373976, -2.8090274 ,\n",
       "        0.37032035, -0.11138176, -0.75362706, -0.99798024,  0.995906  ,\n",
       "        0.75686324,  0.728502  ,  0.24512796,  0.04841153,  0.15038326,\n",
       "       -1.3985827 ,  1.6801823 , -0.04201328, -1.2874738 ,  0.42331356,\n",
       "        0.11637232, -0.3131694 , -0.83214194, -0.8186776 ,  0.13544294,\n",
       "        0.3881726 ,  1.255925  ,  0.18629244, -0.9984687 ,  0.03413611,\n",
       "        0.72361624,  0.7804538 ,  0.01775291,  0.89437497,  1.1820703 ,\n",
       "       -0.41846913, -2.2209003 , -1.4436356 ,  0.5315743 ,  2.5332532 ,\n",
       "        1.4248586 ,  0.90145385,  1.3810599 , -1.4961717 ,  1.3634588 ,\n",
       "        0.55895525,  0.4158344 , -1.0962096 , -0.3156733 ,  1.6593226 ,\n",
       "        0.28837633, -2.2876787 ,  0.08219571, -0.03177314, -0.20914511,\n",
       "        0.6544573 ,  2.2617037 , -0.3834827 ,  0.65421885, -1.018916  ,\n",
       "       -0.03432648,  1.6475209 ,  0.8538151 ,  1.7610021 ,  0.26132262,\n",
       "       -0.07152647,  0.25944713,  0.98815197, -0.64581776,  0.03969196,\n",
       "        1.5517476 , -1.2957491 ,  0.40898898,  0.22393776,  0.5088073 ,\n",
       "       -1.7689742 ,  0.8691631 ,  1.6679947 ,  0.37520978, -0.02451871,\n",
       "       -0.85538495,  1.1691244 , -0.7967418 , -1.1566502 , -1.2493602 ,\n",
       "       -0.8064523 ,  0.14297937,  1.2946856 ,  0.9516396 , -1.5989649 ,\n",
       "       -1.1606678 , -0.231853  ,  1.5449656 ,  0.17001626,  1.0399381 ,\n",
       "        0.55228573,  0.9676975 ,  1.7900296 , -0.74899125, -0.39072224,\n",
       "        0.03439876,  0.1396919 , -1.0094469 ,  1.5966926 ,  0.853771  ,\n",
       "        1.7712957 , -0.02379836,  0.6713703 , -0.14294693, -1.2005277 ,\n",
       "       -0.61009234,  0.6670369 , -0.643715  , -1.6132421 , -1.6726853 ,\n",
       "       -0.00395755, -0.37089318,  1.7485971 ,  0.18315893, -0.34356222,\n",
       "       -0.7816989 , -1.2950623 ,  0.35440165,  1.6622176 ,  0.9187613 ,\n",
       "       -0.12106578, -0.54698825,  0.04070929,  1.1610692 ,  0.3108925 ,\n",
       "       -0.8581708 , -0.0565592 , -0.5534888 , -0.22646165,  1.0764819 ,\n",
       "        0.93313617,  0.23757564,  0.2455228 , -1.0179067 ,  0.37129125],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test word2vec model\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound'\")\n",
    "wv_model.wv.most_similar('sound', topn=5)\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound' but not relevant to 'film'\")\n",
    "wv_model.wv.most_similar(positive=['sound','music'], \\\n",
    "                         negative=['film'], topn=5)\n",
    "\n",
    "print(\"Similarity between 'movie' and 'film':\")\n",
    "wv_model.wv.similarity('movie','film') \n",
    "\n",
    "print(\"Similarity between 'movie' and 'city':\")\n",
    "wv_model.wv.similarity('movie','city') \n",
    "\n",
    "print(\"Word does not match with others in the list of \\\n",
    "['sound', 'music', 'graphics', 'actor', 'book']:\")\n",
    "wv_model.wv.doesnt_match([\"sound\", \"music\", \\\n",
    "                          \"graphics\", \"actor\", \"book\"])\n",
    "\n",
    "print(\"Word vector for 'movie':\")\n",
    "wv_model.wv['movie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Pretrained Word Vectors\n",
    "- Google published pre-trained 300-dimensional vectors for 3 million words and phrases that were trained on Google News dataset (about 100 billion words)(https://code.google.com/archive/p/word2vec/)\n",
    "- GloVe (Global Vectors for Word Representation): Pretained word vectors from different data sources provided by Standford https://nlp.stanford.edu/projects/glove/\n",
    "- FastText by Facebook https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "- Contextualized BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load glove embedding (trained from wikipedia)\n",
    "\n",
    "from embeddings import GloveEmbedding, FastTextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "g = GloveEmbedding('wikipedia_gigaword', d_emb=100, show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31154001  0.028206    0.79364997 -0.45298001  0.45264    -0.098082\n",
      "  0.015137   -0.42804    -0.31727999  0.23111001 -0.005192   -0.13428\n",
      " -0.57582003  0.26732999  0.46024001 -0.37432    -0.26615    -0.43922001\n",
      "  0.48126999  0.38863999  0.29482001 -0.17739999  0.53140002 -1.2586\n",
      " -0.156       0.21075    -0.46983999  0.43877     0.32132     0.19392\n",
      " -0.037995    0.42976001 -0.44771999  0.81957     0.034205   -0.86826998\n",
      " -0.19284999 -0.30478999  0.68098998 -1.2529      0.27992001 -0.56071001\n",
      " -0.81357998  0.76863003 -0.26093999 -0.26960999  0.30458    -0.15528999\n",
      "  0.22773001 -1.15760005 -0.16664    -0.16254     0.16587999  0.20457\n",
      "  0.32515001 -2.54590011  0.7597      0.005298    1.30369997  0.14820001\n",
      "  0.36361     1.20210004 -0.87075001 -0.016171    0.13203    -0.28979999\n",
      "  0.42447999 -0.04421    -0.12926    -0.60518003  0.056072    0.33465999\n",
      "  0.85614997 -0.66035998  0.77411002 -0.21391     0.14384    -0.12709001\n",
      "  0.038184   -0.62795001  0.14861    -0.36488    -0.19199     0.51923001\n",
      " -1.69319999  0.64565003  0.51885998 -0.88296002 -0.40193    -0.31090999\n",
      "  0.12065    -0.10001    -0.58616     0.11359    -0.010166    0.36715001\n",
      " -1.41569996 -0.62902999  0.77177    -0.21413   ]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the vectors for all the words \n",
    "\n",
    "wv_dim = 100\n",
    "\n",
    "words = ['sound', 'music', 'graphics', 'actor', 'book']\n",
    "vectors = np.zeros((len(words), wv_dim))\n",
    "\n",
    "for i, w in enumerate(words):\n",
    "    wv = g.lookup(w)\n",
    "    if wv:\n",
    "        vectors[i] = wv\n",
    "\n",
    "# show vector of 'sound'\n",
    "print(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.68927389, 0.41086313, 0.3166927 , 0.32444362],\n",
       "       [0.68927389, 1.        , 0.31041093, 0.43786326, 0.54355895],\n",
       "       [0.41086313, 0.31041093, 1.        , 0.15638935, 0.27588037],\n",
       "       [0.3166927 , 0.43786326, 0.15638935, 1.        , 0.34439448],\n",
       "       [0.32444362, 0.54355895, 0.27588037, 0.34439448, 1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show similarity between words\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. How to use word vectors in classification?\n",
    "\n",
    "`Convolutional Neural Network`\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2017/10/Depiction-of-the-multiple-channel-convolutional-neural-network-for-text.png\" width =\"100%\">\n",
    "\n",
    "`Recurrent Neural Network`\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/graviraja/100-Days-of-NLP/master/assets/images/applications/sentiment/simple.gif\" width = \"90%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. More Advanced Transformer Model for Contextualized Embeddings\n",
    "\n",
    "\n",
    "<img src=\"https://sp-ao.shortpixel.ai/client/q_glossy,ret_img,w_780/https://conscient.ai/wp-content/uploads/2019/09/2-4.jpg\" width = \"90%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
